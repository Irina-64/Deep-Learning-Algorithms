{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Irina-64/Deep-Learning-Algorithms/blob/main/%D0%91%D0%B0%D0%B7%D0%BE%D0%B2%D0%BE%D0%B5_%D0%94%D0%97_FlowerClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJHy7vziiPnC"
      },
      "source": [
        "# ДЗ. Классификация цветов\n",
        "\n",
        "### Продолжим работать с [Датасетом](https://www.kaggle.com/alxmamaev/flowers-recognition ) для классификации цветов (тюльпан, ромашка, подсолнух, роза, одуванчик)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подключаем google drive чтобы хранить на нем папку с изображениями"
      ],
      "metadata": {
        "id": "JjmJ_-JFhphX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "id": "tAU5a2M9hjSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скачиваем архив по ссылке, распаковываем и сохраняем в google drive в папку flowers"
      ],
      "metadata": {
        "id": "xGxIv_OghnIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('flowers.zip'):\n",
        "  !wget https://www.dropbox.com/s/qmfzqc056oiwy8c/flowers.zip\n",
        "if not os.path.exists('drive/MyDrive/flowers'):\n",
        "  !unzip flowers.zip -d drive/MyDrive/"
      ],
      "metadata": {
        "id": "VYU5hR0Shj3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRteSKZ5VKai"
      },
      "source": [
        "# Подготовка датасета и функции для обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXtAgtr2V3u6"
      },
      "source": [
        "Загружаем библиотеки. Фиксируем random.seed для воспроизводимости"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvM84NDjxCnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14065d0-777c-435c-92d3-ff73ebaa5ec2"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f42edca7a70>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjYDp6nXWWmQ"
      },
      "source": [
        "Выбираем на чем будем делать вычисления - CPU или GPU (cuda)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzyQGtNfzMsI",
        "outputId": "e5885321-b1e6-4ec5-ac7d-d9d525f5d75e"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV-txOlLyJhK"
      },
      "source": [
        "prepare_imgs = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.Resize((224, 224)), #приводим картинки к одному размеру\n",
        "        torchvision.transforms.ToTensor(), # упаковывем их в тензор\n",
        "        torchvision.transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] # нормализуем картинки по каналам\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "# задаем датасет. Лейблы - имена папок:\n",
        "dataset = ImageFolder('drive/MyDrive/flowers', transform=prepare_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcuefCcB8iwi",
        "outputId": "9b711b2a-ab4a-4aee-b66f-8143c696aadc"
      },
      "source": [
        "dataset.imgs[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('drive/MyDrive/flowers/daisy/10172379554_b296050f82_n.jpg', 0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_DuonGn5HVb"
      },
      "source": [
        "class ValueMeter(object):\n",
        "  \"\"\"\n",
        "  Вспомогательный класс, чтобы отслеживать loss и метрику\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "      self.sum = 0\n",
        "      self.total = 0\n",
        "\n",
        "  def add(self, value, n):\n",
        "      self.sum += value*n\n",
        "      self.total += n\n",
        "\n",
        "  def value(self):\n",
        "      return self.sum/self.total\n",
        "\n",
        "def log(mode, epoch, loss_meter, accuracy_meter, best_perf=None):\n",
        "  \"\"\"\n",
        "  Вспомогательная функция, чтобы\n",
        "  \"\"\"\n",
        "  print(\n",
        "      f\"[{mode}] Epoch: {epoch:0.2f}. \"\n",
        "      f\"Loss: {loss_meter.value():.2f}. \"\n",
        "      f\"Accuracy: {100*accuracy_meter.value():.2f}% \", end=\"\\n\")\n",
        "\n",
        "  if best_perf:\n",
        "      print(f\"[best: {best_perf:0.2f}]%\", end=\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP0M3cL8ZDd3"
      },
      "source": [
        "### Задаем параметры и функцию для обучения. Разбиваем датасет на train/validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwhX2vdquink"
      },
      "source": [
        "batch_size = 32 # размер батча\n",
        "lr = 0.001 # learning rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG0zjMWDYu32"
      },
      "source": [
        "Разбиваем датасет на train и validation\n",
        "\n",
        "Задаем dataloader'ы - объекты для итеративной загрузки данных и лейблов для обучения и валидации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2AW1YTupITs",
        "outputId": "a951d05d-aa6c-40d4-8482-e944b9388c4a"
      },
      "source": [
        "train_set, val_set = torch.utils.data.random_split(dataset, [len(dataset)-1000, 1000])\n",
        "print('Размер обучающего и валидационного датасета: ', len(train_set), len(val_set))\n",
        "loaders = {'training': DataLoader(train_set, batch_size, pin_memory=True,num_workers=2, shuffle=True),\n",
        "           'validation':DataLoader(val_set, batch_size, pin_memory=True,num_workers=2, shuffle=False)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер обучающего и валидационного датасета:  3317 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuiJKWrYZZgb"
      },
      "source": [
        "Функция для подсчета Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm15u4TsDcIY"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzW60Io-riGV"
      },
      "source": [
        "Функция для обучения и валидации модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdlXyjEGhU4W"
      },
      "source": [
        "def trainval(model, loaders, optimizer, epochs=10):\n",
        "    \"\"\"\n",
        "    model: модель, которую собираемся обучать\n",
        "    loaders: dict с dataloader'ами для обучения и валидации\n",
        "    optimizer: оптимизатор\n",
        "    epochs: число обучающих эпох (сколько раз пройдемся по всему датасету)\n",
        "    \"\"\"\n",
        "    loss_meter = {'training': ValueMeter(), 'validation': ValueMeter()}\n",
        "    accuracy_meter = {'training': ValueMeter(), 'validation': ValueMeter()}\n",
        "\n",
        "    loss_track = {'training': [], 'validation': []}\n",
        "    accuracy_track = {'training': [], 'validation': []}\n",
        "\n",
        "    for epoch in range(epochs): # итерации по эпохам\n",
        "        for mode in ['training', 'validation']: # обучение - валидация\n",
        "            # считаем градиаент только при обучении:\n",
        "            with torch.set_grad_enabled(mode == 'training'):\n",
        "                # в зависимоти от фазы переводим модель в нужный ружим:\n",
        "                model.train() if mode == 'training' else model.eval()\n",
        "                for imgs, labels in tqdm(loaders[mode]):\n",
        "                    imgs = imgs.to(device) # отправляем тензор на GPU\n",
        "                    labels = labels.to(device)\n",
        "                    bs = labels.shape[0]  # размер батча (отличается для последнего батча в лоадере)\n",
        "\n",
        "                    preds = model(imgs) # forward pass - прогоняем тензор с картинками через модель\n",
        "                    loss = F.cross_entropy(preds, labels) # считаем функцию потерь\n",
        "                    acc = accuracy(preds, labels) # считаем метрику\n",
        "\n",
        "                    # храним loss и accuracy для батча\n",
        "                    loss_meter[mode].add(loss.item(), bs)\n",
        "                    accuracy_meter[mode].add(acc, bs)\n",
        "\n",
        "                    # если мы в фазе обучения\n",
        "                    if mode == 'training':\n",
        "                        optimizer.zero_grad() # обнуляем прошлый градиент\n",
        "                        loss.backward() # делаем backward pass (считаем градиент)\n",
        "                        optimizer.step() # обновляем веса\n",
        "            # в конце фазы выводим значения loss и accuracy\n",
        "            log(mode, epoch, loss_meter[mode], accuracy_meter[mode])\n",
        "\n",
        "            # сохраняем результаты по всем эпохам\n",
        "            loss_track[mode].append(loss_meter[mode].value())\n",
        "            accuracy_track[mode].append(accuracy_meter[mode].value())\n",
        "    return loss_track, accuracy_track"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJFCbGkObf_4"
      },
      "source": [
        "def set_parameter_requires_grad(model):\n",
        "  \"\"\"\n",
        "  Функция для заморозки весов модели\n",
        "  \"\"\"\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rtKZrQF0oma"
      },
      "source": [
        "# Домашнее задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27qiLUtR011m"
      },
      "source": [
        "В домашнем задании попробуем обучить еще одну сверточную архитектуру.\n",
        "\n",
        "1) Разберите более детально код выше (или код с практики, они идентичны). Запустите весь код в этом ноутбуке.\n",
        "\n",
        "\n",
        "2) Посмотрите как задаются [модели сверточных сетей в PyTorch](https://pytorch.org/vision/stable/models.html), выберите одну модель из списка:\n",
        "\n",
        "*   alexnet\n",
        "*   vgg16\n",
        "*   mobilenet_v2\n",
        "*   mobilenet_v3_small\n",
        "*   densenet\n",
        "\n",
        "3) Дообучите выбранную модель для задачи классификации цветов, по аналогии с тем, как мы дообучали resnet18 на занятии. Чтобы это сделать замените ____ в ячейках ниже на код. Где-то надо вставить нужную переменную, где-то прописать константу. Главное не пугайтесь! Аналогичный код можно найти в ноутбуке с практикой ;)\n",
        "\n",
        "4) Если вам интересно, прочитайте дополнительно про эти архитектуры. Можно почитать [здесь (на английском)](https://medium.com/@fransiska26/the-differences-between-inception-resnet-and-mobilenet-e97736a709b0) или [здесь (на русском)](https://habr.com/ru/company/nix/blog/430524/)\n",
        "\n",
        "**Совет 1:** загрузите папку с картинками на гугл диск, чтобы не загружать ее каждый раз заново при перезапуске колаба. Структура файлов (можно посмотреть в меню слева) должна быть такой: drive/MyDrive/flowers\n",
        "\n",
        "**Совет 2:** обязательно подключите аппаратный ускоритель (GPU) к среде выполнения, чтобы вычисления были. В меню сверху: Среда выполнения -> Сменить среду выполнения\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZGKQ77DqT31"
      },
      "source": [
        "# Выберите модель из списка доступных в PyTorch моделей\n",
        "# Не забудьте указать, что она модель должна быть предобучена!\n",
        "model = torchvision.models._____\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zVgqf7x4aOo"
      },
      "source": [
        "set_parameter_requires_grad(_____) # передайте модель в функцию для \"заморозки\" градиента"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXqwU5Rd5DYs"
      },
      "source": [
        "model._____ = _____# Меняем последний слой модели"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaquxdRWJ_LK"
      },
      "source": [
        "# Проверим все ли сработало правильно, выведем веса, которые будут обучаться\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTE0EUG9lh5g"
      },
      "source": [
        "model.to(_____) # Отправляем модель на GPU\n",
        "optimizer = torch.optim.Adam(params = model.parameters()) # алгоритм оптимизации\n",
        "loss_track, accuracy_track = trainval(model, loaders, optimizer, epochs=_____) # запускаем обучение, задаем количество эпох"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}